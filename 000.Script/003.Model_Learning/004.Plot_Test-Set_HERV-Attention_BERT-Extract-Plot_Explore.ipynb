{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from datasets import Dataset, DatasetDict \n",
    "from collections import Counter\n",
    "#from high_attention import kmer2seq, plot_random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataset_name=\"BERT_HERV_Multi_RUN0\"\n",
    "output_dir=\"/home/u20111010010/Project/DNA-Pretraining/Level1/003.Sequence_Visualization/Dataset_HERV\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=\"/home/u20111010010/Project/DNA-Pretraining/Level1/001.Genomics_dataset/Dataset_HERV/VCF_hprc-1000G/Train_Test/data_all_model_HERV-Classification_Need.fa\"\n",
    "df1=pd.read_csv(file,sep=\"\\t\",header=None).rename(columns = {0: \"dset\", 1: \"multi\",2:\"binary\", 3: \"seq\",4:\"Type\",5: \"detail\"})\n",
    "df = df1.loc[:, ['dset', 'multi','seq']]\n",
    "df = df[df['dset'] == 'test']\n",
    "\n",
    "print(\"+++++++++++++++++++++++++++++Test sets\")\n",
    "print(df.shape)\n",
    "\n",
    "\n",
    "### label间转换\n",
    "id2label={\"0\":\"Non-HERV_Coding\",\"1\":\"HERV_Coding\",\"2\":\"Non-HERV_Non-Coding\",\"3\":\"HERV_Non-Coding\"}\n",
    "labels_raw=list(df['multi'])\n",
    "labels = [id2label[str(i)] for i in labels_raw]\n",
    "\n",
    "print(Counter(labels))\n",
    "\n",
    "sequences=list(df['seq'])\n",
    "#df[\"seq1\"] = df[\"seq\"].apply(kmer2seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 字体设置\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "from matplotlib.font_manager import FontManager\n",
    "FontManager()._findfont_cached.cache_clear()\n",
    "\n",
    "#font_path = \"/home/u20111010010/Project/DNA-Pretraining/Level1/Manuscript/Times_New_Roman/Times New Roman.ttf\"\n",
    "\n",
    "### 正常字体\n",
    "font_path =\"/home/u20111010010/Project/DNA-Pretraining/Level1/Manuscript/Times_New_Roman/Times_New_Roman.ttf\"\n",
    "\n",
    "### 粗体\n",
    "#font_path =\"/home/u20111010010/Project/DNA-Pretraining/Level1/Manuscript/Times_New_Roman/Times New Roman Bold.ttf\"\n",
    "#plt.rcParams['font.family'] = 'Times New Roman'\n",
    "#plt.rcParams['font.serif'] = font_path\n",
    "\n",
    "import matplotlib.font_manager as fm\n",
    "fm.fontManager.addfont(font_path)\n",
    "plt.rcParams['font.family'] = 'Times New Roman'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contiguous_regions(condition, len_thres=5):\n",
    "    \"\"\"\n",
    "    从布尔数组 \"condition\" 中查找连续的 True 区域。\n",
    "    返回一个二维数组，其中第一列是区域的开始索引，第二列是结束索引。\n",
    "    \"\"\"\n",
    "    # 找到 \"condition\" 中变化的索引\n",
    "    d = np.diff(condition)\n",
    "    (idx,) = d.nonzero()\n",
    "    # 因为我们需要在 \"condition\" 变化之后开始，所以右移一位\n",
    "    idx += 1\n",
    "    if condition[0]:\n",
    "        # 如果 condition 开始为 True，前面加一个 0\n",
    "        idx = np.r_[0, idx]\n",
    "    if condition[-1]:\n",
    "        # 如果 condition 结束为 True，添加数组的长度\n",
    "        idx = np.r_[idx, condition.size]\n",
    "    # 将结果重塑为两列\n",
    "    idx.shape = (-1, 2)\n",
    "    # 剔除那些不满足长度阈值的区域\n",
    "    idx = idx[np.argwhere((idx[:, 1] - idx[:, 0]) >= len_thres).flatten()]\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_high_attention(score, min_len=5, **kwargs):\n",
    "    \"\"\"\n",
    "    使用注意力得分数组作为输入，找到长度大于 min_len 的连续高注意力子区域的索引。\n",
    "    \"\"\"\n",
    "    # 创建两个条件来定义\"高注意力\"\n",
    "    cond1 = score > np.mean(score)\n",
    "    cond2 = score > 10 * np.min(score)\n",
    "    # 合并这两个条件\n",
    "    cond = [cond1, cond2]\n",
    "    cond = list(map(all, zip(*cond)))\n",
    "    # 如果提供了自定义条件，则使用它们\n",
    "    if \"cond\" in kwargs:\n",
    "        cond = kwargs[\"cond\"]\n",
    "        if any(isinstance(x, list) for x in cond):\n",
    "            cond = list(map(all, zip(*cond)))\n",
    "    cond = np.asarray(cond)\n",
    "    # 查找具有高注意力的连续区域\n",
    "    motif_regions = contiguous_regions(cond, min_len)\n",
    "    return motif_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_range_to_dna_range(start_token_idx, end_token_idx, dna_length, kmer_size=6):\n",
    "    actual_kmers = dna_length - kmer_size + 1  # 实际的 k-mer 数量\n",
    "    # 如果 start_token_idx 超过了 actual_kmers，返回空\n",
    "    if start_token_idx >= actual_kmers:\n",
    "        return 0, 0\n",
    "    # 如果 end_token_idx 超过了 actual_kmers，将其限制为 actual_kmers - 1\n",
    "    if end_token_idx >= actual_kmers:\n",
    "        end_token_idx = actual_kmers - 1\n",
    "    # 判断 start_token 是否在前 300 个\n",
    "    if start_token_idx < 300:\n",
    "        start_dna_idx = start_token_idx\n",
    "    else:\n",
    "        # 为后212个tokens计算偏移量\n",
    "        offset = start_token_idx - 300\n",
    "        start_dna_idx = actual_kmers - (212 - offset)\n",
    "    # 判断 end_token 是否在前 300 个\n",
    "    if end_token_idx < 300:\n",
    "        end_dna_idx = end_token_idx + kmer_size - 1\n",
    "    else:\n",
    "        # 为后212个tokens计算偏移量\n",
    "        offset = end_token_idx - 300\n",
    "        end_dna_idx = actual_kmers - (212 - offset) + kmer_size - 1\n",
    "    return start_dna_idx, end_dna_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_seq(attentions, sequences, out_dir, min_len=5, window=4, indices=None, name=\"All\"):\n",
    "    \"\"\"\n",
    "    根据注意力得分，找到具有高注意力的 DNA 序列区域，并保存为 FASTA 格式。\n",
    "    \"\"\"\n",
    "    # 如果输出目录不存在，创建它\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "    # 如果注意力得分是 2D 的，说明只有一个注意力得分\n",
    "    if len(attentions.shape) == 2:\n",
    "        print(\"Processing Single Attention Scores.\")\n",
    "        with open(os.path.join(out_dir, \"{}_high_attention.fa\".format(name)), \"w\") as fa:\n",
    "            # 对每个注意力得分和序列进行迭代\n",
    "            for index, attention, sequence in zip(range(attentions.shape[0]), attentions, sequences):\n",
    "                # 找到高注意力区域\n",
    "                motif_regions = find_high_attention(attention, min_len)\n",
    "                for motif_idx in motif_regions:\n",
    "                    # 根据motif_idx转换为对应的DNA范围\n",
    "                    start_dna_idx, end_dna_idx = token_range_to_dna_range(motif_idx[0], motif_idx[1], len(sequence))\n",
    "                    # 考虑窗口大小进行调整\n",
    "                    safe_start = max(start_dna_idx - window, 0)\n",
    "                    safe_end = min(end_dna_idx + window, len(sequence))\n",
    "                    if(safe_end<0):print(\"+++++++++++++++++++++++++++++++++++++++++++\",motif_idx[0], motif_idx[1], len(sequence))\n",
    "                    # 提取对应的DNA子序列\n",
    "                    seq = sequence[safe_start:safe_end]\n",
    "                    to_write = \">{}_{}_{}\\n\".format(index, safe_start, safe_end)\n",
    "                    to_write += seq + \"\\n\"\n",
    "                    fa.write(to_write)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型学习到的Attention矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 行数等于输入序列的数量,列数等于模型的last_hidden_state中的特征数量(768)\n",
    "# /home/u20111010010/Project/DNA-Pretraining/Level1/003.Sequence_Visualization/Dataset_HERV/BERT_HERV_Multi_RUN0_extract_single_attentions.npy\n",
    "atten_scores=np.load(os.path.join(output_dir, \"BERT_HERV_Multi_RUN0_extract_single_attentions.npy\"))\n",
    "#np.save(os.path.join(output_dir, \"BERT_HERV_Multi_RUN0_extract_unnorm_attentions.npy\"), unnorm)\n",
    "#np.save(os.path.join(output_dir, \"BERT_HERV_Multi_RUN0_extract_multi_attentions.npy\"), multi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据和注意力得分按类型拆分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "### 找到 label 列中值为 1 或 2 的行的索引\n",
    "\n",
    "indices_0 = np.where(df['multi'] == 0)[0]\n",
    "indices_1 = np.where(df['multi'] == 1)[0]\n",
    "indices_2 = np.where(df['multi'] == 2)[0]\n",
    "indices_3 = np.where(df['multi'] == 3)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 数据和注意力矩阵分割\n",
    "df_0 = df.iloc[indices_0]\n",
    "atten_scores_0=atten_scores[indices_0]\n",
    "df_1 = df.iloc[indices_1]\n",
    "atten_scores_1=atten_scores[indices_1]\n",
    "df_2 = df.iloc[indices_2]\n",
    "atten_scores_2=atten_scores[indices_2]\n",
    "df_3 = df.iloc[indices_3]\n",
    "atten_scores_3=atten_scores[indices_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "#{\"0\":\"Non-HERV_Coding\",\"1\":\"HERV_Coding\",\"2\":\"Non-HERV_Non-Coding\",\"3\":\"HERV_Non-Coding\"}\n",
    "all_datasets = [df_0, df_1, df_2,df_3]\n",
    "all_attens = [atten_scores_0,atten_scores_1,atten_scores_2,atten_scores_3]\n",
    "\n",
    "colors = sns.color_palette(\"deep\", 4) \n",
    "# 定义标签到颜色的映射\n",
    "id2color = {\n",
    "        'Non-HERV_Coding': colors[0],\n",
    "        'HERV_Coding': colors[1],\n",
    "        'HERV_Non-Coding': colors[2],\n",
    "        'Non-HERV_Non-Coding': colors[3]\n",
    "    }\n",
    "all_names = [\"Non-HERV_Coding\", \"HERV_Coding\", \"Non-HERV_Non-Coding\",\"HERV_Non-Coding\"]\n",
    "all_colors = [id2color[all_names[0]],id2color[all_names[1]], id2color[all_names[2]], id2color[all_names[3]]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 平均注意力趋势（ average trend）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### 正常显示\n",
    "MIN_SEQ_LEN = 8\n",
    "WINDOW=4\n",
    "for i in range(len(all_attens)):\n",
    "    dataset = all_datasets[i]\n",
    "    atten = all_attens[i]\n",
    "    name = all_names[i]\n",
    "    color = all_colors[i]\n",
    "    '''\n",
    "    # Run the Sequence Extraction and Visualization\n",
    "    attention_seq(atten, dataset[\"seq\"], min_len=MIN_SEQ_LEN, \n",
    "              window=WINDOW, name=name,\n",
    "              out_dir=\"BERT_attention_seqs\")\n",
    "    print(\"Saved sequence file for {}.\".format(name))\n",
    "    '''\n",
    "    ## <preprocess or split your data>\n",
    "    avg = np.average(atten, 0)\n",
    "    x_values = list(range(len(avg)))\n",
    "    # Create a plot using matplotlib\n",
    "    plt.plot(x_values, avg, linestyle=\"-\", color=color, label=name)\n",
    "\n",
    "    \n",
    "    \n",
    "plt.title(f\"\")  # Use 'title' instead of 'set_title'\n",
    "plt.xlabel(\"BERT Tokens(Base)\")  # Use 'xlabel' instead of 'set_xlabel'\n",
    "plt.ylabel(\"Average Local Representation Weighted (ALRW) Scores\")  # Use 'ylabel' instead of 'set_ylabel'\n",
    "plt.legend(loc='upper right')\n",
    "# Show the plot\n",
    "#plt.subplots_adjust(left=0.1, right=0.95, bottom=0.1, top=0.95)\n",
    "#plt.xticks(rotation=45, va='center', fontsize=9, fontweight='bold')\n",
    "\n",
    "# 设置轴标题的样式\n",
    "#ax.set_xlabel('X Axis Title', fontsize=9, fontweight='bold')\n",
    "#ax.set_ylabel('Y Axis Title', fontsize=9, fontweight='bold')\n",
    "\n",
    "plt.savefig(f\"{dataset_name}-All_Attention-trend_visualization.pdf\")\n",
    "plt.savefig(f\"{dataset_name}-All_Attention-trend_visualization.png\")\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### 仅显示部分plt.ylim(0, 0.15) ############################################################################ 正文\n",
    "MIN_SEQ_LEN = 8\n",
    "WINDOW=4\n",
    "\n",
    "plt.subplots(figsize=(4,3))\n",
    "#plt.rcParams['xtick.labelsize'] = 8\n",
    "#plt.rcParams['ytick.labelsize'] = 8\n",
    "#plt.rcParams[\"font.family\"] = prop.get_name()\n",
    "\n",
    "for i in range(len(all_attens)):\n",
    "    dataset = all_datasets[i]\n",
    "    atten = all_attens[i]\n",
    "    name = all_names[i]\n",
    "    color = all_colors[i]\n",
    "    ## <preprocess or split your data>\n",
    "    avg = np.average(atten, 0)\n",
    "    x_values = list(range(len(avg)))\n",
    "    # Create a plot using matplotlib\n",
    "    plt.plot(x_values, avg, linestyle=\"-\", color=color, label=name)\n",
    "\n",
    "plt.title(f\" \")  # Use 'title' instead of 'set_title', #BERT Attention Plot\n",
    "fontdict_bold = {'fontsize': 6} #, 'weight': 'bold'}\n",
    "\n",
    "plt.xlabel(\"BERT Tokens(Base)\",fontdict=fontdict_bold)  # Use 'xlabel' instead of 'set_xlabel'\n",
    "plt.ylabel(\"Average Local Representation Weighted (ALRW) Scores\",fontdict=fontdict_bold) #,fontsize=9,labelweight='bold')  # Use 'ylabel' instead of 'set_ylabel'\n",
    "\n",
    "plt.tick_params(axis='both', which='major', labelsize=6) \n",
    "plt.legend(loc='upper left',bbox_to_anchor=(0.05, 1),fontsize=6)\n",
    "plt.tight_layout() \n",
    "plt.ylim(0, 0.15)\n",
    "# Show the plot\n",
    "plt.subplots_adjust(left=0.1, right=0.95, bottom=0.1, top=0.95)\n",
    "\n",
    "plt.savefig(f\"{dataset_name}-All_Attention-trend_visualization_part.pdf\")\n",
    "plt.savefig(f\"{dataset_name}-All_Attention-trend_visualization_part.png\",dpi = 2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'all_attens', 'all_datasets', 'all_names', 'all_colors', 'dataset_name' are defined\n",
    "# For this example, these variables need to be defined earlier in your code.\n",
    "# If they are not defined, you will need to provide the data for these variables.\n",
    "\n",
    "plt.subplots(figsize=(8,6))\n",
    "\n",
    "# Iterate through each dataset and plot the attention scores\n",
    "for i in range(len(all_attens)):\n",
    "    dataset = all_datasets[i]\n",
    "    atten = all_attens[i]\n",
    "    name = all_names[i]\n",
    "    color = all_colors[i]\n",
    "    # Preprocess or split your data if necessary\n",
    "    avg = np.average(atten, 0)\n",
    "    x_values = list(range(len(avg)))\n",
    "    plt.plot(x_values, avg, linestyle=\"-\", color=color, label=name)\n",
    "\n",
    "# Set the title of the plot\n",
    "plt.title(\"BERT Attention Plot\")\n",
    "\n",
    "# Define font dictionary for bold labels\n",
    "fontdict_bold = {'fontsize': 12, 'weight': 'bold'}\n",
    "\n",
    "# Set x and y labels with bold font\n",
    "plt.xlabel(\"BERT Tokens(Base)\", fontdict=fontdict_bold)\n",
    "plt.ylabel(\"Average Local Representation Weighted (ALRW) Scores\", fontdict=fontdict_bold)\n",
    "\n",
    "# Set other plot properties\n",
    "plt.tick_params(axis='both', which='major', labelsize=9)\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(0.05, 1))\n",
    "plt.tight_layout()\n",
    "plt.ylim(0, 0.15)\n",
    "\n",
    "# Adjust subplot parameters and save the plot\n",
    "plt.subplots_adjust(left=0.1, right=0.95, bottom=0.1, top=0.95)\n",
    "plt.savefig(f\"{dataset_name}-All_Attention-trend_visualization_part.pdf\")\n",
    "plt.savefig(f\"{dataset_name}-All_Attention-trend_visualization_part.png\", dpi=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 展示多头注意力情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\n",
    "    \"blue\",  # Blue\n",
    "    \"green\",  # Green\n",
    "    \"red\",  # Red\n",
    "    \"purple\",  # Purple\n",
    "    \"orange\",  # Orange\n",
    "    \"brown\",  # Brown\n",
    "    \"pink\",  # Pink\n",
    "    \"gray\",  # Gray\n",
    "    \"olive\",  # Olive\n",
    "    \"cyan\",  # Cyan\n",
    "    \"magenta\",  # Magenta\n",
    "    \"teal\",  # Teal\n",
    "]\n",
    "\n",
    "def plot_multi_line(list_values):\n",
    "    x_values = list(range(len(list_values[0])))\n",
    "    fig, axs = plt.subplots(3, 4, figsize=(12, 9))\n",
    "    axs = axs.flatten()\n",
    "    for i, ax in enumerate(axs):\n",
    "        ax.plot(x_values, list_values[i], linestyle=\"-\", color=colors[i])\n",
    "        ax.set_title(f\"Plot for Head {i+1}\")\n",
    "        ax.set_xlabel(\"Base Pair\")\n",
    "        ax.set_ylabel(\"Average Attention for Head\")\n",
    "    plt.tight_layout()\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_multi_line2(list_values, list_values1):\n",
    "    x_values = list(range(len(list_values[0])))\n",
    "    fig, axs = plt.subplots(3, 4, figsize=(15, 10), sharex=True)\n",
    "    axs = axs.ravel()\n",
    "    for i, ax in enumerate(axs):\n",
    "        ax.plot(x_values, list_values[i], linestyle=\"-\", color=\"red\", label=\"Others\" if i == 0 else \"\")\n",
    "        ax.plot(x_values, list_values1[i], linestyle=\"-\", color=\"green\", label=\"HERV_Non-Coding\" if i == 0 else \"\")\n",
    "        ax.set_title(f\"Plot for Head {i+1}\")\n",
    "        ax.set_xlabel(\"Base Pair\")\n",
    "        ax.set_ylabel(\"Average Attention for Head\")\n",
    "        # Set the y-axis limit based on the maximum value in both list_values and list_values1 for this subplot\n",
    "        max_val = max(max(list_values[i]), max(list_values1[i]))\n",
    "        ax.set_ylim([0, max_val * 1.1])  # Set upper limit to 10% higher than the max value\n",
    "        ax.tick_params(axis='both', which='major', labelsize=9)\n",
    "    # Create a single legend for the whole figure\n",
    "    handles, labels = axs[0].get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5, 1.02), ncol=2, fontsize='large')\n",
    "    plt.tight_layout() #rect=[0, 0.03, 1, 0.95]\n",
    "\n",
    "\n",
    "def plot_multi_line2(list_values, list_values1):\n",
    "    x_values = list(range(len(list_values[0])))\n",
    "    fig, axs = plt.subplots(3, 4, figsize=(15, 10), sharex=True)\n",
    "    axs = axs.ravel()\n",
    "    for i, ax in enumerate(axs):\n",
    "        ax.plot(x_values, list_values[i], linestyle=\"-\", color=\"red\", label=\"Others\" if i == 0 else \"\")\n",
    "        ax.plot(x_values, list_values1[i], linestyle=\"-\", color=\"green\", label=\"HERV_Non-Coding\" if i == 0 else \"\")\n",
    "        ax.set_title(f\"Plot for Head {i+1}\")\n",
    "        ax.set_xlabel(\"Base Pair\")\n",
    "        ax.set_ylabel(\"Average Attention for Head\")\n",
    "        # Set the y-axis limit based on the maximum value in both list_values and list_values1 for this subplot\n",
    "        max_val = max(max(list_values[i]), max(list_values1[i]))\n",
    "        ax.set_ylim([0, max_val * 1.1])  # Set upper limit to 10% higher than the max value\n",
    "        ax.tick_params(axis='both', which='major', labelsize=9)\n",
    "    # Create a single legend for the whole figure and place it below the subplots\n",
    "    handles, labels = axs[0].get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5, 1.0), ncol=2, fontsize='large')\n",
    "    # Adjust the layout to make room for the legend\n",
    "    # The rect argument defines the (left, bottom, right, top) rectangle in normalized figure coordinates that the whole subplots area (including labels) will fit into\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    # Show the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 所有类型序列平均得分\n",
    "multi_scores=np.load(os.path.join(output_dir, \"BERT_HERV_Multi_RUN0_extract_multi_attentions.npy\"))\n",
    "# Loading in attention scores from atten.npy. Please note that this currently uses a small sample of MHA scores.\n",
    "\n",
    "multi_average = np.average(multi_scores, 0)\n",
    "plot_multi_line(multi_average)\n",
    "plt.savefig(f\"{dataset_name}-All_Multi-Header_Attention-trend_visualization.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### HERV_Non-Coding\n",
    "multi_scores_3=multi_scores[indices_3]\n",
    "multi_average_3 = np.average(multi_scores_3, 0)\n",
    "plot_multi_line(multi_average_3)\n",
    "plt.savefig(f\"{dataset_name}-All_Multi-Header_Attention-trend_visualization-HERV_Non-Coding.pdf\")\n",
    "plt.savefig(f\"{dataset_name}-All_Multi-Header_Attention-trend_visualization-HERV_Non-Coding.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Others\n",
    "multi_scores_012=multi_scores[np.concatenate([indices_0, indices_1, indices_2])]\n",
    "multi_average_012 = np.average(multi_scores_012, 0)\n",
    "plot_multi_line2(multi_average_012,multi_average_3)\n",
    "plt.savefig(f\"{dataset_name}-All_Multi-Header_Attention-trend_visualization-HERV_Non-Coding#Other.pdf\")\n",
    "plt.savefig(f\"{dataset_name}-All_Multi-Header_Attention-trend_visualization-HERV_Non-Coding#Other.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 根据Tokens区间评估区域内DNA序列特性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 对给定的DNA序列计算一系列的特征的函数\n",
    "def evaluate_dataset(sequences, kmer=6):\n",
    "    gc_contents = []\n",
    "    kmer_frequencies = []\n",
    "    shannon_entropies = []\n",
    "    cpg_island_scores = []\n",
    "    for sequence in sequences:\n",
    "        if len(sequence) == 0:\n",
    "            # Append NaN for sequences of length 0\n",
    "            gc_contents.append(np.nan)\n",
    "            kmer_frequencies.append(np.nan)\n",
    "            shannon_entropies.append(np.nan)\n",
    "            cpg_island_scores.append(np.nan)\n",
    "            continue\n",
    "        # Calculate GC content\n",
    "        gc_content = (sequence.count('G') + sequence.count('C')) / len(sequence)\n",
    "        gc_contents.append(gc_content)\n",
    "        # Calculate kmer frequency\n",
    "        if len(sequence) - kmer + 1 > 0:\n",
    "            kmers = [sequence[i:i+kmer] for i in range(len(sequence) - kmer + 1)]\n",
    "            kmer_freq = len(set(kmers)) / (len(sequence) - kmer + 1)\n",
    "            kmer_frequencies.append(kmer_freq)\n",
    "        else:\n",
    "            kmer_frequencies.append(np.nan)\n",
    "        # Calculate Shannon entropy\n",
    "        prob = [float(sequence.count(c)) / len(sequence) for c in dict.fromkeys(list(sequence))]\n",
    "        prob = [p for p in prob if p > 0]\n",
    "        shannon_entropy = -sum(p * np.log2(p) for p in prob)\n",
    "        shannon_entropies.append(shannon_entropy)\n",
    "        # CpG island\n",
    "        cg_count = sequence.count('CG')\n",
    "        c_freq = sequence.count('C') / len(sequence)\n",
    "        g_freq = sequence.count('G') / len(sequence)\n",
    "        expected_cg_count = c_freq * g_freq * len(sequence)\n",
    "        # Ensure we don't get a division by zero\n",
    "        if expected_cg_count != 0:\n",
    "            cpg_score = cg_count / expected_cg_count\n",
    "        else:\n",
    "            cpg_score = np.nan\n",
    "        cpg_island_scores.append(cpg_score)\n",
    "    return gc_contents, kmer_frequencies, shannon_entropies, cpg_island_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为数据集中的每个标签评估DNA特征的函数\n",
    "def evaluate_dna_characteristics(df, labels, token_ranges):\n",
    "    results_dict = {}\n",
    "    for label in labels:\n",
    "        sequences = df[df['multi'] == label]['seq']\n",
    "        dna_lengths = sequences.apply(len)\n",
    "        results = []\n",
    "        for index, dna_length in enumerate(dna_lengths):\n",
    "            sequence = sequences.iloc[index]\n",
    "            sub_results = []\n",
    "            for start, end in token_ranges:\n",
    "                start_dna_idx, end_dna_idx = token_range_to_dna_range(start, end, dna_length)\n",
    "                subsequence = sequence[start_dna_idx:end_dna_idx]\n",
    "                gc, kmer_freq, shannon,cpg = evaluate_dataset([subsequence])\n",
    "                sub_results.append([gc, kmer_freq, shannon,cpg])\n",
    "            results.append(sub_results)\n",
    "        # 存储每个label的结果\n",
    "        results_dict[label] = np.nanmean(results, axis=0)\n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 相应指标计算\n",
    "\n",
    "# 假设 df 包含了一个 'label' 列，其中的值为 \"A\", \"B\", \"C\" 或 \"D\"\n",
    "labels = [0, 1, 2, 3]\n",
    "id2label={\"0\":\"Non-HERV_Coding\",\"1\":\"HERV_Coding\",\"2\":\"Non-HERV_Non-Coding\",\"3\":\"HERV_Non-Coding\"}\n",
    "token_ranges = [(0, 50), (50, 150), (150, 250), (250, 350), (350, 450), (450, 512)]\n",
    "results_dict = evaluate_dna_characteristics(df, labels, token_ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 格式转化使其变成便于操作的DataFrame数据格式\n",
    "dfs = []\n",
    "\n",
    "for label in labels:\n",
    "    data = np.squeeze(results_dict[label])  # 去除单一维度\n",
    "    #df_label = pd.DataFrame(data, columns=[\"GC\", \"6-mer\", \"Shannon\",\"CpG\"])\n",
    "    df_label = pd.DataFrame(data, columns=[\"GC_Content\",\"6-mer_Freq\",\"Shannon_Entropy\",\"CpG-Island_Score\"])\n",
    "    df_label.columns = [f\"{id2label[str(label)]}_{col}\" for col in df_label.columns]\n",
    "    dfs.append(df_label)\n",
    "\n",
    "# 沿列轴连接所有的DataFrame\n",
    "df_results = pd.concat(dfs, axis=1)\n",
    "\n",
    "# 使用token_ranges作为行名\n",
    "df_results['Token Ranges'] = [f\"{start}-{end}\" for start, end in token_ranges]\n",
    "df_results.set_index('Token Ranges', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 折线图进行基因组各项特征展示（所有特征合并在一起）\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you've already defined df_results, token_ranges, and dataset_name\n",
    "features = [\"GC\", \"6-mer\", \"Shannon\", \"CpG\"]\n",
    "features1 = [\"GC_Content\",\"K-mer_Freq\",\"Shannon_Entropy\",\"CpG-Island_Score\"]\n",
    "labels = [\"Non-HERV_Coding\", \"HERV_Coding\", \"Non-HERV_Non-Coding\", \"HERV_Non-Coding\"]\n",
    "# Define markers for each feature\n",
    "feature_markers = {\n",
    "    \"GC\": \"o\",       # Circle\n",
    "    \"6-mer\": \"s\",    # Square\n",
    "    \"Shannon\": \"^\",  # Triangle up\n",
    "    \"CpG\": \"D\"       # Diamond\n",
    "}\n",
    "# Define colors for each label\n",
    "feature_markers1 = {\"GC_Content\": \"o\",\"K-mer_Freq\": \"s\",\"Shannon_Entropy\": \"^\",\"CpG-Island_Score\": \"D\" }\n",
    "label_colors = id2color\n",
    "\n",
    "fig, ax = plt.subplots()  # Increase figure size，figsize=(9, 9)\n",
    "x = np.arange(len(token_ranges))\n",
    "\n",
    "# Plot lines for each combination of label and feature\n",
    "for i, feature in enumerate(features):\n",
    "    for j, label in enumerate(labels):\n",
    "        y_values = df_results[f\"{label}_{feature}\"]\n",
    "        ax.plot(x, y_values, color=label_colors[label], marker=feature_markers[feature], \n",
    "                label=f\"{label} {feature}\" if i == 0 else \"\", \n",
    "                alpha=0.7, linewidth=1.5,markersize=6)  # Adjust opacity and line width\n",
    "\n",
    "# Setting labels, title, and legends\n",
    "ax.set_ylabel('Value')\n",
    "ax.set_xlabel('BERT Tokens Region')  # Add X-axis label\n",
    "ax.set_title('Comparison of DNA Characteristics across Different Labels and Token Ranges',fontsize=10)  ###,fontsize=4\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([f\"{start}-{end}\" for start, end in token_ranges])\n",
    "\n",
    "# Expand Y-axis limits slightly\n",
    "ylim = ax.get_ylim()\n",
    "y_padding = (ylim[1] - ylim[0]) * 0.4\n",
    "ax.set_ylim(ylim[0], ylim[1] + y_padding)\n",
    "\n",
    "# Create separate legends for colors and shapes\n",
    "from matplotlib.lines import Line2D\n",
    "legend_elements_colors = [Line2D([0], [0], color=c, lw=2, label=l) for l, c in label_colors.items()]\n",
    "legend_elements_shapes = [Line2D([0], [0], color='black', marker=m, lw=0, label=f) for f, m in feature_markers1.items()]\n",
    "\n",
    "# Add legends\n",
    "leg1 = ax.legend(handles=legend_elements_colors, loc='upper left')\n",
    "ax.add_artist(leg1)\n",
    "ax.legend(handles=legend_elements_shapes, loc='upper right')\n",
    "\n",
    "# Rotate x-axis labels\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save figures\n",
    "plt.savefig(f\"{dataset_name}-All_Attention_Tokens-Region_DNA_Characteristics-trend_visualization-line.pdf\")\n",
    "plt.savefig(f\"{dataset_name}-All_Attention_Tokens-Region_DNA_Characteristics-trend_visualization-line.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 折线图进行基因组各项特征展示（所有特征分开绘图）,######################################################################## 正文\n",
    "# 创建子图，减少子图之间的间隙\n",
    "features = [\"Shannon_Entropy\", \"GC_Content\", \"CpG-Island_Score\"]\n",
    "labels = [\"Non-HERV_Coding\", \"HERV_Coding\", \"Non-HERV_Non-Coding\", \"HERV_Non-Coding\"]\n",
    "\n",
    "import seaborn as sns\n",
    "colors = sns.color_palette(\"deep\", 4) \n",
    "# 定义标签到颜色的映射\n",
    "id2color = {'Non-HERV_Coding': colors[0],'HERV_Coding': colors[1],'HERV_Non-Coding': colors[2],'Non-HERV_Non-Coding': colors[3]}\n",
    "\n",
    "# 创建子图，减少子图之间的间隙\n",
    "fig, axs = plt.subplots(3, 1, figsize=(4,3), sharex=True, gridspec_kw={'hspace': 0.005})   #figsize=(8,8)\n",
    "plt.rcParams['xtick.labelsize'] = 3\n",
    "plt.rcParams['ytick.labelsize'] = 3\n",
    "\n",
    "handles_list, labels_list = [], []  # 存储所有图例的句柄和标签\n",
    "x = np.arange(len(token_ranges))\n",
    "\n",
    "for i, feature in enumerate(features):\n",
    "    # 收集所有特征的值\n",
    "    all_values = []\n",
    "    ax = axs[i]\n",
    "    for j, label in enumerate(labels):\n",
    "        y_values = df_results[f\"{label}_{feature}\"]\n",
    "        all_values.extend(y_values)\n",
    "        #line_color = plt.rcParams['axes.prop_cycle'].by_key()['color'][j]\n",
    "        #line, = ax.plot(x, y_values, color=id2color[j], alpha=0.7, linewidth=1.5, marker='o', markersize=6)\n",
    "        line, = ax.plot(x, y_values, color=id2color[label], linestyle=\"-\")\n",
    "        if i == 0:  # 避免图例句柄和标签的重复添加\n",
    "            handles_list.append(line)\n",
    "            labels_list.append(label)\n",
    "    ax.set_ylabel(feature,fontsize=6) #, fontweight='bold')  # 设置Y轴标签\n",
    "    # 设置Y轴的刻度标签，首先要设置刻度位置\n",
    "    y_ticks = np.linspace(min(all_values), max(all_values), 5)\n",
    "    ax.set_yticks(y_ticks)\n",
    "    # 然后设置刻度标签，并确保字体大小与X轴一致\n",
    "    ax.set_yticklabels([f\"{y:.2f}\" for y in y_ticks], fontsize=5.6)\n",
    "    #ax.set_yticklabels([f\"{val:.2f}\" for val in np.linspace(y_values.min(), y_values.max(), len(ax.get_xticks()))], fontsize=5.6)\n",
    "    if i < len(features) - 1:  # 对于非最后一个子图，隐藏x轴标签\n",
    "        plt.setp(ax.get_xticklabels(), visible=False)\n",
    "        \n",
    "# 设置最后一个子图的X轴标签\n",
    "fontdict_bold = {'fontsize': 6} #, 'weight': 'bold'}\n",
    "\n",
    "axs[-1].set_xlabel('BERT Tokens(Region)',fontdict = fontdict_bold)\n",
    "axs[-1].set_xticks(x)\n",
    "axs[-1].set_xticklabels([f\"{start}-{end}\" for start, end in token_ranges], rotation=0, ha=\"center\",fontsize=5.6)  ##fontsize=9, fontweight='bold'\n",
    "\n",
    "# 在子图1的右上角创建整体图例\n",
    "# 注意：bbox_to_anchor的值可能需要根据您的具体布局进行微调\n",
    "#legend = fig.legend(handles_list, labels_list, loc='upper left', bbox_to_anchor=(0.675, 0.8))\n",
    "#plt.tight_layout(rect=[0, 0, 0.85, 1])  # 为图例留出空间\n",
    "#plt.subplots_adjust(left=0.1, right=0.95, bottom=0.1, top=0.95)\n",
    "\n",
    "# 打印绘图的默认字体\n",
    "print(plt.rcParams['font.family'])\n",
    "plt.subplots_adjust(left=0.1, right=0.95, bottom=0.1, top=0.95)\n",
    "# Save figures\n",
    "plt.savefig(f\"{dataset_name}-All_Attention_Tokens-Region_DNA_Characteristics-trend_visualization-line.pdf\")\n",
    "plt.savefig(f\"{dataset_name}-All_Attention_Tokens-Region_DNA_Characteristics-trend_visualization-line.png\",dpi = 2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 柱状图进行基因组特征展示（分特征绘图）\n",
    "features = [\"6-mer_Freq\", \"Shannon_Entropy\", \"GC_Content\", \"CpG-Island_Score\"]\n",
    "labels = [\"Non-HERV_Coding\", \"HERV_Coding\", \"Non-HERV_Non-Coding\", \"HERV_Non-Coding\"]\n",
    "x = np.arange(len(token_ranges))  # 每个token区间的标签位置\n",
    "width = 0.2  # 柱状图的宽度\n",
    "\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "with PdfPages(f\"{dataset_name}-All_Attention_Tokens-Region_DNA_Characteristics-trend_visualization.pdf\") as pdf:\n",
    "    for i, feature in enumerate(features):\n",
    "        fig, ax = plt.subplots(figsize=(15, 7))\n",
    "        for j, label in enumerate(labels):\n",
    "            data_label_feature = f\"{label}_{feature}\"\n",
    "            # 在这里，我们不再将feature添加到图例的标签中\n",
    "            ax.bar(x + j * width, df_results[data_label_feature], width, label=label,color=id2color[label])  # 已移除 `f\"{label} {feature}\"`\n",
    "        # 添加标签，标题和图例\n",
    "        ax.set_ylabel('Value')\n",
    "        ax.set_title(f'Comparison of {feature} across Different Labels and Token Ranges')\n",
    "        ax.set_xticks(x + width * (len(labels) - 1) / 2)\n",
    "        ax.set_xticklabels([f\"{start}-{end}\" for start, end in token_ranges])\n",
    "        ax.legend(loc='upper left')  # 图例现在只包含标签\n",
    "        # 旋转x轴标签以避免重叠\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        # 保存当前的图形到PDF文件\n",
    "        pdf.savefig(fig)\n",
    "    # plt.show()  # 这将仅在最后显示最终的图形；如果您希望每生成一个图形就显示，需要将此行移动到循环中\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.1.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
